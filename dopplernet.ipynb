{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0caf3ba12ae5c83a31dbb936f428f9780d24709e45786b11451eaa6ab07208891",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import RadarImageTargetSet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "ds = RadarImageTargetSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "for (img, tgt) in ds:\n",
    "    for box in tgt['boxes']:\n",
    "        boxes.append(box)\n",
    "boxes = np.array(boxes)\n",
    "box_xsizes = boxes[:, 2] - boxes[:, 0]\n",
    "box_ysizes = boxes[:, 3] - boxes[:, 1]\n",
    "max_x_size = int(max(box_xsizes))\n",
    "max_y_size = int(max(box_ysizes))\n",
    "\n",
    "print(max_x_size, max_y_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data for DopplerNet like model\n",
    "\n",
    "# box cutouts\n",
    "x = []\n",
    "# box center positions in radar frame\n",
    "c = []\n",
    "# classes in one hot encoding\n",
    "y = []\n",
    "for (img, tgt) in ds:\n",
    "    #print(img.shape)\n",
    "    for (class_type, (y0, x0, y1, x1)) in zip(tgt['labels'], list(tgt['boxes'])):\n",
    "        if np.isclose(class_type, 3.0): \n",
    "            continue\n",
    "        c.append([0.5 * (x0 + x1), 0.5 * (y0 + y1)])\n",
    "        # cut box out of image\n",
    "        #print(class_type)\n",
    "        #print(x0, y0, x1, y1)\n",
    "        cutout = img[int(x0):int(x1), int(y0):int(y1)]\n",
    "        #print(cutout.shape)\n",
    "        if cutout.shape[0] > max_x_size and cutout.shape[1] > max_y_size:\n",
    "            print(\"can't process box of shape\", x0, y0, x1, y1, cutout.shape)\n",
    "            continue\n",
    "        # padding putting it in upper left corner\n",
    "        # TODO: center\n",
    "        y_padding = int(max_y_size - cutout.shape[0])\n",
    "        x_padding = int(max_x_size - cutout.shape[1])\n",
    "        padded = np.pad(cutout, ((y_padding // 2, y_padding - (y_padding // 2)), (x_padding // 2, x_padding - (x_padding // 2))), mode='constant', constant_values=0.0)\n",
    "        x.append(padded)\n",
    "        # class as one hot encoding\n",
    "        y.append([1.0 if int(class_type) == i else 0.0 for i in range(4)])\n",
    "\n",
    "x = np.array(x)\n",
    "c = np.array(c)\n",
    "y = np.array(y)\n",
    "print(x.shape)\n",
    "print(c.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,c_train,c_test,y_train,y_test=train_test_split(x, c, y, test_size=0.33, random_state=42)\n",
    "\n",
    "x_train=np.asarray(x_train)\n",
    "c_train=np.asarray(c_train)\n",
    "y_train=np.asarray(y_train)\n",
    "x_test=np.asarray(x_test)\n",
    "c_test=np.asarray(c_test)\n",
    "y_test=np.asarray(y_test)\n",
    "x_train=np.reshape(x_train,[-1,11,27,1])\n",
    "c_train=np.reshape(c_train,[-1,2,1])\n",
    "x_test=np.reshape(x_test,[-1,11,27,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "#from k.layers.Input as Input\n",
    "#from k.layers.Conv2D as Conv2D\n",
    "\n",
    "#model=k.Sequential()\n",
    "#model.add(tf.keras.Input(shape=(11,27,1)))\n",
    "#model.add(k.layers.Conv2D(32,3,3,padding='valid',\n",
    "#    dilation_rate=(1, 1),\n",
    "#    activation=\"relu\"))\n",
    "#model.add(k.layers.Flatten())\n",
    "#model.add(k.layers.Dense(64,activation=\"relu\"))\n",
    "#model.add(k.layers.Dense(64,activation=\"relu\"))\n",
    "#model.add(k.layers.Dense(64,activation=\"relu\"))\n",
    "#model.add(k.layers.Dense(64,activation=\"relu\"))\n",
    "#model.add(k.layers.Dense(4,activation=\"softmax\"))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.summary()\n",
    "#TODO: parallel input of absolute box position \n",
    "ridge = 5e-5\n",
    "dropout = 0\n",
    "# define two sets of inputs\n",
    "inputA = Input(shape=(11,27,1))\n",
    "inputB = Input(shape=(2,))\n",
    "# the first branch operates on the first input\n",
    "x = k.layers.Conv2D(32,3,3,padding='same',\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(ridge),\n",
    "    bias_regularizer=regularizers.l2(ridge))(inputA)\n",
    "# x = Dropout(dropout)(x)\n",
    "x = k.layers.Conv2D(32,3,3,padding='same',\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(ridge),\n",
    "    bias_regularizer=regularizers.l2(ridge))(x)\n",
    "# x = Dropout(dropout)(x)\n",
    "x = k.layers.Flatten()(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(1, activation=\"linear\")(inputB)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(64, activation=\"relu\",    \n",
    "    kernel_regularizer=regularizers.l2(ridge),\n",
    "    bias_regularizer=regularizers.l2(ridge))(combined)\n",
    "z = Dense(64, activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(ridge),\n",
    "    bias_regularizer=regularizers.l2(ridge))(z)\n",
    "z = Dense(64, activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(ridge),\n",
    "    bias_regularizer=regularizers.l2(ridge))(z)\n",
    "z = Dense(4, activation=\"softmax\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "history=model.fit(x = [x_train, c_train], y = y_train, epochs=EPOCHS,batch_size=374, validation_data=([x_test, c_test], y_test)) \n",
    "# set batch size to number of images in dataset ==> slower training but minority class is consicerd in every parameter update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=history.model.predict([x_test, c_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(range(1,EPOCHS+1),history.history['loss'], label='validation loss')\n",
    "\n",
    "#plt.plot(range(1,EPOCHS+1),history.history['accuracy'], label='validation accuracy')\n",
    "#plt.legend()\n",
    "#plt.show(\n",
    "# plot accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.ylim((0, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.evaluate([x_test, c_test] ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_abs = np.argmax(y_pred, axis=1)\n",
    "y_test_abs = np.argmax(y_test, axis=1)\n",
    "cm=confusion_matrix(y_test_abs,y_pred_abs)\n",
    "plt.imshow(cm)\n",
    "print(cm)\n",
    "\n",
    "print(y_pred[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross validation\n",
    "if __name__ == \"__main__\":\n",
    "    n_folds = 10\n",
    "    data, labels, header_info = load_data()\n",
    "    skf = StratifiedKFold(labels, n_folds=n_folds, shuffle=True)\n",
    "\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "            print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "            model = None # Clearing the NN.\n",
    "            model = create_model()\n",
    "            train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])"
   ]
  }
 ]
}